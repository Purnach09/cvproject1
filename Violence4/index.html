<!DOCTYPE html>
<html style="font-size: 16px;" lang="en"><head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="utf-8">
    <meta name="keywords" content="Violence Detection using Computer vision, Introduction, Existing Approach​​, Proposed Approach, Architecture, Methodology">
    <meta name="description" content="">
    <title>Home</title>
    <link rel="stylesheet" href="nicepage.css" media="screen">
<link rel="stylesheet" href="Home.css" media="screen">
    <script class="u-script" type="text/javascript" src="jquery.js" defer=""></script>
    <script class="u-script" type="text/javascript" src="nicepage.js" defer=""></script>
    <meta name="generator" content="Nicepage 4.18.5, nicepage.com">
    <link id="u-theme-google-font" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:100,100i,300,300i,400,400i,500,500i,700,700i,900,900i|Open+Sans:300,300i,400,400i,500,500i,600,600i,700,700i,800,800i">
    
    
    
    
    
    
    
    
    <script type="application/ld+json">{
		"@context": "http://schema.org",
		"@type": "Organization",
		"name": ""
}</script>
    <meta name="theme-color" content="#478ac9">
    <meta property="og:title" content="Home">
    <meta property="og:type" content="website">
  </head>
  <body data-home-page="Home.html" data-home-page-title="Home" class="u-body u-xl-mode" data-lang="en"><header class="u-clearfix u-header u-sticky u-sticky-9d31 u-header" id="sec-d36c"><div class="u-clearfix u-sheet u-sheet-1">
        <nav class="u-menu u-menu-one-level u-offcanvas u-menu-1">
          <div class="menu-collapse" style="font-size: 1rem; letter-spacing: 0px;">
            <a class="u-button-style u-custom-left-right-menu-spacing u-custom-padding-bottom u-custom-top-bottom-menu-spacing u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="#">
              <svg class="u-svg-link" viewBox="0 0 24 24"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#menu-hamburger"></use></svg>
              <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><symbol id="menu-hamburger" viewBox="0 0 16 16" style="width: 16px; height: 16px;"><rect y="1" width="16" height="2"></rect><rect y="7" width="16" height="2"></rect><rect y="13" width="16" height="2"></rect>
</symbol>
</defs></svg>
            </a>
          </div>
          <div class="u-custom-menu u-nav-container">
            <ul class="u-nav u-unstyled u-nav-1"><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="Home.html" style="padding: 10px 20px;">Home</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="Home.html#carousel_40bc" style="padding: 10px 20px;">Introduction</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="Home.html#carousel_2d8c" style="padding: 10px 20px;">Architecture</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="Home.html#carousel_660d" style="padding: 10px 20px;">Methodology</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="Home.html#carousel_b85d" style="padding: 10px 20px;">Conclusion</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="Home.html#sec-f80a" style="padding: 10px 20px;">Quiz</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="Home.html#sec-7ed1" style="padding: 10px 20px;">References</a>
</li></ul>
          </div>
          <div class="u-custom-menu u-nav-container-collapse">
            <div class="u-black u-container-style u-inner-container-layout u-opacity u-opacity-95 u-sidenav">
              <div class="u-sidenav-overflow">
                <div class="u-menu-close"></div>
                <ul class="u-align-center u-nav u-popupmenu-items u-unstyled u-nav-2"><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Home.html">Home</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Home.html#carousel_40bc">Introduction</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Home.html#carousel_2d8c">Architecture</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Home.html#carousel_660d">Methodology</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Home.html#carousel_b85d">Conclusion</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Home.html#sec-f80a">Quiz</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Home.html#sec-7ed1">References</a>
</li></ul>
              </div>
            </div>
            <div class="u-black u-menu-overlay u-opacity u-opacity-70"></div>
          </div>
        </nav>
      </div></header>
    <section class="u-align-center u-clearfix u-image u-shading u-section-1" src="" data-image-width="500" data-image-height="281" id="sec-1a5a">
      <div class="u-align-center u-clearfix u-sheet u-sheet-1">
        <h2 class="u-text u-text-default u-text-1">Violence Detection using Computer vision</h2>
        <p class="u-text u-text-2">Purnachandram Chittimilla</p>
      </div>
    </section>
    <section class="u-carousel u-slide u-block-987f-1" src="" data-image-width="256" data-image-height="256" id="carousel_40bc" data-interval="5000" data-u-ride="carousel">
      <ol class="u-absolute-hcenter u-carousel-indicators u-block-987f-2">
        <li data-u-target="#carousel_40bc" data-u-slide-to="0" class="u-active u-grey-30"></li>
        <li data-u-target="#carousel_40bc" class="u-grey-30" data-u-slide-to="1"></li>
      </ol>
      <div class="u-carousel-inner" role="listbox">
        <div class="u-active u-align-center u-carousel-item u-clearfix u-image u-shading u-section-2-1" src="" data-image-width="256" data-image-height="256">
          <div class="u-clearfix u-sheet u-sheet-1">
            <h1 class="u-text u-text-default u-title u-text-1">Introduction</h1>
            <p class="u-align-center u-large-text u-text u-text-variant u-text-2">Over the most recent couple of years, the issue of human activity acknowledgment from the video has
gotten manageable by utilizing PC vision strategies, see reviews. Inside this theme, there is tremendous
writing wherein test results are given for acknowledgment of human activities like strolling, bouncing, or
hand waving. In any case, activity identification has been dedicated less to exertion. Activity recognition
is a connected errand where just a particular activity should be identified. Activity location might be of
directuse,all things considered,applications,battleidentificationbeingareasonablemodel.Thoughthere
are a few very much read datasets for activity acknowledgment, huge datasets with brutal activities
(battles) have not been made accessible until the work. A brutality locator has, not with standing, quick
pertinence in the observation area. The essential capacity of enormous scope reconnaissance frameworks
sent in establishments like schools, jails, and mental consideration offices is for making specialists aware
of possibly perilous circumstances. Not with standing, human administrators are overpowered with the
quantity of camera feeds and manual reaction times are moderate, bringing about a solid interest for
computerized ready frameworks. Essentially, there is expanding interest in computerized rating and
labeling frameworks that can interact with the incredible amounts of video transferred to sites.&nbsp;</p>
          </div>
        </div>
        <div class="u-align-center u-carousel-item u-clearfix u-image u-shading u-section-2-2" src="" data-image-width="256" data-image-height="256">
          <div class="u-clearfix u-sheet u-sheet-1">
            <h2 class="u-align-left u-text u-text-body-color u-text-default u-text-1">
              <span style="font-size: 1.5rem; font-weight: 700;">Existing Approach</span>
              <span style="font-size: 0.875rem;">
                <span style="font-size: 1rem;"></span>
              </span>
            </h2>
            <p class="u-large-text u-text u-text-variant u-text-2"><b>
                <span style="font-size: 1.5rem;">
                  <span style="font-weight: 400;">Surveillance systems are very common in today’s society but most of the existing systems rely on human observers for detecting activities from these videos.</span>&nbsp;
                </span></b>
              <br>
              <br><b>Approach ran on 14 videos of which 7 are violence videos and 7 are non-violence videos.</b>
              <br>
              <br>
            </p>
            <h2 class="u-text u-text-body-color u-text-3">Proposed Approach</h2>
            <p class="u-large-text u-text u-text-variant u-text-4"><b>
                <span style="font-weight: 400;">To run the approach on three different datasets:</span></b>
              <br><b>
                <span style="font-weight: 400;">Hockey Dataset</span></b>
              <br><b>Football Dataset</b>
              <br><b>Boxing Dataset</b>
              <br><b>To train the Neural Network model on the above 3 datasets by adding additional layers.</b>
              <br><b>To create a Visualized platform to classify the video as Violence or Non-Violence.</b>
              <br>
            </p>
          </div>
        </div>
      </div>
      <a class="u-absolute-vcenter u-carousel-control u-carousel-control-prev u-text-grey-30 u-block-987f-3" href="#carousel_40bc" role="button" data-u-slide="prev">
        <span aria-hidden="true">
          <svg class="u-svg-link" viewBox="0 0 477.175 477.175"><path d="M145.188,238.575l215.5-215.5c5.3-5.3,5.3-13.8,0-19.1s-13.8-5.3-19.1,0l-225.1,225.1c-5.3,5.3-5.3,13.8,0,19.1l225.1,225
                    c2.6,2.6,6.1,4,9.5,4s6.9-1.3,9.5-4c5.3-5.3,5.3-13.8,0-19.1L145.188,238.575z"></path></svg>
        </span>
        <span class="sr-only">Previous</span>
      </a>
      <a class="u-absolute-vcenter u-carousel-control u-carousel-control-next u-text-grey-30 u-block-987f-4" href="#carousel_40bc" role="button" data-u-slide="next">
        <span aria-hidden="true">
          <svg class="u-svg-link" viewBox="0 0 477.175 477.175"><path d="M360.731,229.075l-225.1-225.1c-5.3-5.3-13.8-5.3-19.1,0s-5.3,13.8,0,19.1l215.5,215.5l-215.5,215.5
                    c-5.3,5.3-5.3,13.8,0,19.1c2.6,2.6,6.1,4,9.5,4c3.4,0,6.9-1.3,9.5-4l225.1-225.1C365.931,242.875,365.931,234.275,360.731,229.075z"></path></svg>
        </span>
        <span class="sr-only">Next</span>
      </a>
    </section>
    <section class="u-carousel u-slide u-block-7d65-1" id="carousel_2d8c" data-interval="5000" data-u-ride="carousel">
      <ol class="u-absolute-hcenter u-carousel-indicators u-block-7d65-2">
        <li data-u-target="#carousel_2d8c" data-u-slide-to="0" class="u-active u-grey-30"></li>
      </ol>
      <div class="u-carousel-inner" role="listbox">
        <div class="u-active u-carousel-item u-clearfix u-section-3-1">
          <div class="u-clearfix u-sheet u-valign-middle u-sheet-1">
            <div class="fr-view u-align-center u-clearfix u-rich-text u-text u-text-1">
              <h1 style="text-align: center;">Architecture</h1>
              <p style="text-align: center;">
                <span style="line-height: 2.0;">
                  <img src="images/ScreenShot2022-09-29at00.59.43.png" align="center" style="width: 583px;" class="fr-dib fr-fic" width="570">&nbsp;
                </span>
              </p>
            </div>
          </div>
        </div>
      </div>
      <a class="u-absolute-vcenter u-carousel-control u-carousel-control-prev u-text-grey-30 u-block-7d65-3" href="#carousel_2d8c" role="button" data-u-slide="prev">
        <span aria-hidden="true">
          <svg class="u-svg-link" viewBox="0 0 477.175 477.175"><path d="M145.188,238.575l215.5-215.5c5.3-5.3,5.3-13.8,0-19.1s-13.8-5.3-19.1,0l-225.1,225.1c-5.3,5.3-5.3,13.8,0,19.1l225.1,225
                    c2.6,2.6,6.1,4,9.5,4s6.9-1.3,9.5-4c5.3-5.3,5.3-13.8,0-19.1L145.188,238.575z"></path></svg>
        </span>
        <span class="sr-only">Previous</span>
      </a>
      <a class="u-absolute-vcenter u-carousel-control u-carousel-control-next u-text-grey-30 u-block-7d65-4" href="#carousel_2d8c" role="button" data-u-slide="next">
        <span aria-hidden="true">
          <svg class="u-svg-link" viewBox="0 0 477.175 477.175"><path d="M360.731,229.075l-225.1-225.1c-5.3-5.3-13.8-5.3-19.1,0s-5.3,13.8,0,19.1l215.5,215.5l-215.5,215.5
                    c-5.3,5.3-5.3,13.8,0,19.1c2.6,2.6,6.1,4,9.5,4c3.4,0,6.9-1.3,9.5-4l225.1-225.1C365.931,242.875,365.931,234.275,360.731,229.075z"></path></svg>
        </span>
        <span class="sr-only">Next</span>
      </a>
    </section>
    <section class="u-carousel u-slide u-block-7655-1" id="carousel_660d" data-interval="5000" data-u-ride="carousel">
      <ol class="u-absolute-hcenter u-carousel-indicators u-block-7655-5">
        <li data-u-target="#carousel_660d" data-u-slide-to="0" class="u-active u-grey-30"></li>
        <li data-u-target="#carousel_660d" class="u-grey-30" data-u-slide-to="1"></li>
        <li data-u-target="#carousel_660d" class="u-grey-30" data-u-slide-to="2"></li>
        <li data-u-target="#carousel_660d" class="u-grey-30" data-u-slide-to="3"></li>
      </ol>
      <div class="u-carousel-inner" role="listbox">
        <div class="u-active u-carousel-item u-clearfix u-section-4-1">
          <div class="u-clearfix u-sheet u-valign-middle u-sheet-1">
            <div class="fr-view u-align-center u-clearfix u-rich-text u-text u-text-1">
              <h1 style="text-align: center;">Methodology</h1>
              <p id="isPasted">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style="font-size: 1.5rem;">&nbsp;This paper proposes a method having three stages mainly, Preprocessing, Feature Extraction, and Classification. Each video goes through the frame skipping method where some frames are omitted from further processing, then they are converted to greyscale which in turn are binarized using thresholding on temporal derivatives. Those binary frames are now subjected to series of morphological operations and noise removal, then those resulting frames will go to feature extraction and subsequently used for classification</span>. &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
              </p>
              <p>&nbsp; &nbsp;&nbsp;</p>
              <p style="text-align: center;">
                <span style="line-height: 2.0;">&nbsp;</span>
              </p>
            </div>
          </div>
        </div>
        <div class="u-carousel-item u-clearfix u-section-4-2">
          <div class="u-clearfix u-gutter-34 u-layout-spacing-top u-layout-wrap u-layout-wrap-1">
            <div class="u-layout">
              <div class="u-layout-row">
                <div class="u-align-left u-container-style u-layout-cell u-left-cell u-size-30 u-white u-layout-cell-1" src="">
                  <div class="u-container-layout u-valign-top u-container-layout-1">
                    <h2 class="u-text u-text-1">
                      <span style="font-size: 1.875rem;">Preprocessing</span>
                    </h2>
                    <p class="u-text u-text-2">Usually, consecutive frames in a video contain redundant data i.e., only a little difference between them.
Calculating temporal derivatives, optical flow on all the consecutive frames may thus cause redundancy
and increase computational complexity which affects the performance of the system. In Movies Dataset
has25fps,i.e.,each frame is captured for every 0.04 second ,which is very insignificant for any reasonable
actions in a fight to occur. Most of the violence detection methods are having more computational
complexity due to this redundancy. Hence, we skip some of the frames in a periodic fashion such that a
noticeable amount of difference is present between consecutive frames.
					For employing this frame skipping method we consider a skipfactor(‘n’),by which we could dynamically
skip the required number of frames based on the data set and frame rate of the videos.<br>&nbsp; &nbsp; &nbsp; &nbsp;Fr = (N/skip factor) ∗ t&nbsp;<br>where Fr is the number of frames retained, N is the frame rate of the video, t is the duration of the video(in
seconds).&nbsp;
                    </p>
                  </div>
                </div>
                <div class="u-container-style u-image u-layout-cell u-right-cell u-size-30 u-image-1" src="" data-image-width="1076" data-image-height="1346">
                  <div class="u-container-layout u-valign-middle u-container-layout-2"></div>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="u-carousel-item u-clearfix u-section-4-3">
          <div class="u-clearfix u-sheet u-sheet-1">
            <div class="u-clearfix u-gutter-0 u-layout-spacing-top u-layout-wrap u-layout-wrap-1">
              <div class="u-layout">
                <div class="u-layout-row">
                  <div class="u-align-left u-container-style u-layout-cell u-left-cell u-size-20 u-white u-layout-cell-1" src="">
                    <div class="u-container-layout u-container-layout-1">
                      <h2 class="u-text u-text-1">Feature Ext​​​raction </h2>
                      <p class="u-text u-text-2">
                        <span style="font-size: 1.5rem;">Key points detection and MoSIFT descriptors<span style="font-weight: 700;"></span>
                        </span>&nbsp;<br>
                        <span style="font-weight: 400;">M<span style="font-size: 1.25rem;">otion in the binary frames is captured at particular local regions in a frame, called Interest points/Key
points.TodetectthesekeypointsweuseatemporalextensionoftheSIFTalgorithm.Descriptorsobtained
at these key points from SIFT are scale and rotation invariant i.e., they are not affected by the size or <br>8
orientation of the frames&nbsp;
                          </span>
                        </span>
                        <br>
                      </p>
                    </div>
                  </div>
                  <div class="u-container-style u-image u-layout-cell u-right-cell u-size-40 u-image-1" src="" data-image-width="1314" data-image-height="1046">
                    <div class="u-container-layout u-valign-middle u-container-layout-2"></div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="u-align-center u-carousel-item u-clearfix u-image u-shading u-section-4-4" src="" data-image-width="256" data-image-height="256">
          <div class="u-clearfix u-sheet u-sheet-1">
            <h1 class="u-text u-text-default u-title u-text-1">Classification</h1>
            <p class="u-large-text u-text u-text-variant u-text-2">Feature vectors obtained from previous steps are now used for binary classification of the videos. Several
Classification techniques including Machine learning and Deep Learning Models are employed to acquire
more accuracy in the area of violence detection. Despite techniques like SVMs, Random forest, and
Adaboost being commonly used and giving good accuracy, we attempt to use a Gradient boosting
technique, XGBoost which uses ensemble learning.
					XGBoost is a distributed and optimized gradient boosting library designed to be highly efficient, portable,
and flexible. Parallel tree boosting (also known as GBDT, GBM) is also provided such that it helps in
classifying in a fast and accurate way. It is a regularised form of Gradient Boosting Machine which has
inbuilt L1 and L2 regularisation to prevent overfitting.&nbsp;</p>
          </div>
        </div>
      </div>
      <a class="u-absolute-vcenter u-carousel-control u-carousel-control-prev u-text-grey-30 u-block-7655-3" href="#carousel_660d" role="button" data-u-slide="prev">
        <span aria-hidden="true">
          <svg class="u-svg-link" viewBox="0 0 477.175 477.175"><path d="M145.188,238.575l215.5-215.5c5.3-5.3,5.3-13.8,0-19.1s-13.8-5.3-19.1,0l-225.1,225.1c-5.3,5.3-5.3,13.8,0,19.1l225.1,225
                    c2.6,2.6,6.1,4,9.5,4s6.9-1.3,9.5-4c5.3-5.3,5.3-13.8,0-19.1L145.188,238.575z"></path></svg>
        </span>
        <span class="sr-only">Previous</span>
      </a>
      <a class="u-absolute-vcenter u-carousel-control u-carousel-control-next u-text-grey-30 u-block-7655-4" href="#carousel_660d" role="button" data-u-slide="next">
        <span aria-hidden="true">
          <svg class="u-svg-link" viewBox="0 0 477.175 477.175"><path d="M360.731,229.075l-225.1-225.1c-5.3-5.3-13.8-5.3-19.1,0s-5.3,13.8,0,19.1l215.5,215.5l-215.5,215.5
                    c-5.3,5.3-5.3,13.8,0,19.1c2.6,2.6,6.1,4,9.5,4c3.4,0,6.9-1.3,9.5-4l225.1-225.1C365.931,242.875,365.931,234.275,360.731,229.075z"></path></svg>
        </span>
        <span class="sr-only">Next</span>
      </a>
    </section>
    <section class="u-carousel u-slide u-block-ee39-1" src="" data-image-width="256" data-image-height="256" id="carousel_b85d" data-interval="5000" data-u-ride="carousel">
      <ol class="u-absolute-hcenter u-carousel-indicators u-block-ee39-2">
        <li data-u-target="#carousel_b85d" data-u-slide-to="0" class="u-active u-grey-30"></li>
        <li data-u-target="#carousel_b85d" class="u-grey-30" data-u-slide-to="1"></li>
      </ol>
      <div class="u-carousel-inner" role="listbox">
        <div class="u-active u-align-center u-carousel-item u-clearfix u-image u-shading u-section-5-1" src="" data-image-width="256" data-image-height="256">
          <div class="u-clearfix u-sheet u-sheet-1">
            <h1 class="u-text u-text-default u-title u-text-1">Conclusion</h1>
            <p class="u-large-text u-text u-text-variant u-text-2">In this project, we attempted to identify the areas of high motion at an early stage of preprocessing by
thresholding on temporal derivatives, which eventually helped to obtain efficient feature ve ctors with
an added advantage of reduced computational complexity. Key points detection on binarised temporal
derivative frames gave more meaningful key points which in turn improved 18the accuracy. As a
result, we have obtained better performance than some of the famous works on violence detection.&nbsp;</p>
          </div>
        </div>
        <div class="u-align-center u-carousel-item u-clearfix u-image u-shading u-section-5-2" src="" data-image-width="256" data-image-height="256">
          <div class="u-clearfix u-sheet u-sheet-1">
            <h1 class="u-text u-text-default u-title u-text-1">Future Scope</h1>
            <p class="u-large-text u-text u-text-default u-text-variant u-text-2">There can still be a few improvements which could be done on this work. Using other encoding
techniques like sparse coding can be done to reduce the redundancy in the feature vector. Kernel
Density Estimation can also be used to efficiently represent descriptors. More efficient spatiotemporal
features can be used to obtain better descriptors.&nbsp;</p>
          </div>
        </div>
      </div>
      <a class="u-absolute-vcenter u-carousel-control u-carousel-control-prev u-text-grey-30 u-block-ee39-3" href="#carousel_b85d" role="button" data-u-slide="prev">
        <span aria-hidden="true">
          <svg class="u-svg-link" viewBox="0 0 477.175 477.175"><path d="M145.188,238.575l215.5-215.5c5.3-5.3,5.3-13.8,0-19.1s-13.8-5.3-19.1,0l-225.1,225.1c-5.3,5.3-5.3,13.8,0,19.1l225.1,225
                    c2.6,2.6,6.1,4,9.5,4s6.9-1.3,9.5-4c5.3-5.3,5.3-13.8,0-19.1L145.188,238.575z"></path></svg>
        </span>
        <span class="sr-only">Previous</span>
      </a>
      <a class="u-absolute-vcenter u-carousel-control u-carousel-control-next u-text-grey-30 u-block-ee39-4" href="#carousel_b85d" role="button" data-u-slide="next">
        <span aria-hidden="true">
          <svg class="u-svg-link" viewBox="0 0 477.175 477.175"><path d="M360.731,229.075l-225.1-225.1c-5.3-5.3-13.8-5.3-19.1,0s-5.3,13.8,0,19.1l215.5,215.5l-215.5,215.5
                    c-5.3,5.3-5.3,13.8,0,19.1c2.6,2.6,6.1,4,9.5,4c3.4,0,6.9-1.3,9.5-4l225.1-225.1C365.931,242.875,365.931,234.275,360.731,229.075z"></path></svg>
        </span>
        <span class="sr-only">Next</span>
      </a>
    </section>
    <section class="u-align-center u-clearfix u-image u-shading u-section-6" src="" data-image-width="256" data-image-height="256" id="sec-f80a">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h1 class="u-text u-text-default u-title u-text-1">Quiz</h1>
        <p class="u-large-text u-text u-text-variant u-text-2">1.Why we gray scale the image?<br>Ans:&nbsp;The range of a digital image's whiteness to blackness is known as grayscale.Grayscaling is the process by which programmers convert a color image to grayscale.This makes the visual data simpler so that a computer can process the input more quickly.<br>
          <br>2.Can you define "digital image?"<br>Ans: A digital image is a picture that's made up of smaller parts, called pixels. These pixels are made of numerical components that represent their color codes and intensity. AI systems us these numbers to understand an image<br>
          <br>3.What programming languages does computer vision support?<br>Ans:Computer vision can use programming languages such as Java, C/C++, Prolog, Phython and LISP. I've primarily used Java in past projects, but I have certification in Prolog as well and basic understanding of the others.
        </p>
      </div>
    </section>
    <section class="u-align-center u-clearfix u-image u-shading u-section-7" src="" data-image-width="256" data-image-height="256" id="sec-7ed1">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h1 class="u-text u-text-default u-title u-text-1">References</h1>
        <p class="u-large-text u-text u-text-variant u-text-2"><b>Febin, I.P., Jayasree, K. &amp; Joy, P.T. “Violence detection in videos for an intelligent surveillance system using MoBSIFT and movement filtering algorithm”. Pattern Analysis and Applications 23, 611–623 (2020).&nbsp;</b>
          <br>
          <br>
          <br><b>MUHAMMAD RAMZAN,, ADNAN ABID , HIKMAT ULLAH KHAN , SHAHID MAHMOOD AWAN AMINA ISMAIL, MUZAMIL AHMED , MAHWISH ILYAS, AND AHSAN MAHMOOD(2019), “A Review on State-of-the-Art Violence Detection Techniques”, IEEE Access, August, 2019.</b>&nbsp;<br>
        </p>
      </div>
    </section>
    
    
    <footer class="u-align-center u-clearfix u-footer u-grey-80 u-footer" id="sec-9668"><div class="u-align-left u-clearfix u-sheet u-sheet-1"></div></footer>
    <section class="u-backlink u-clearfix u-grey-80">
      <a class="u-link" href="https://nicepage.com/website-templates" target="_blank">
        <span>Website Templates</span>
      </a>
      <p class="u-text">
        <span>created with</span>
      </p>
      <a class="u-link" href="" target="_blank">
        <span>Website Builder Software</span>
      </a>. 
    </section>
  
</body></html>